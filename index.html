<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Hidden Bias in Technology</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            line-height: 1.6;
            background: linear-gradient(to right, #2c3e50, #4ca1af);
            color: white;
            text-align: center;
        }
        header {
            background: rgba(0, 0, 0, 0.8);
            color: #fff;
            padding: 30px;
            font-size: 24px;
        }
        section {
            padding: 40px;
            max-width: 900px;
            margin: auto;
            opacity: 0;
            transform: translateY(20px);
            animation: fadeInUp 1s ease-out forwards;
            text-align: left;
        }
        img {
            max-width: 100%;
            display: block;
            margin: 20px auto;
            border-radius: 10px;
        }
        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }
        footer {
            background: rgba(0, 0, 0, 0.8);
            color: #fff;
            text-align: center;
            padding: 15px;
            position: relative;
            bottom: 0;
            width: 100%;
        }
    </style>
</head>
<body>
    <header>
        <h1>The Hidden Bias in Technology: Understanding and Addressing Digital Bias</h1>
        <p><em>Technology is not neutral. Learn how digital bias affects AI and society.</em></p>
    </header>
    
    <section id="introduction">
        <h2>Introduction</h2>
        <p>Artificial Intelligence (AI) and digital systems influence everything from hiring decisions to policing and healthcare. However, biases embedded in these systems can reinforce existing inequalities. This website explores digital bias, its causes, real-world impact, and solutions to ensure fair technology for all.</p>
    </section>
    
    <section id="what-is-bias">
        <h2>What is Digital Bias?</h2>
        <p>Digital bias refers to unintended favoritism or discrimination embedded in AI and algorithms. It happens when technology reflects societal prejudices due to flawed data, poor design, or systemic inequalities.</p>
    </section>
    
    <section id="types">
        <h2>Types of Digital Bias</h2>
        <ul>
            <li><strong>Algorithmic Bias</strong> – AI models generate unfair outcomes due to biased training data.</li>
            <li><strong>Data Bias</strong> – If datasets lack diversity, technology may perform better for some groups than others.</li>
            <li><strong>Design Bias</strong> – Products are created without considering all user demographics.</li>
            <li><strong>Automation Bias</strong> – Users blindly trust AI decisions, even when incorrect.</li>
        </ul>
    </section>
    
    <section id="examples">
        <h2>Real-World Examples of Digital Bias</h2>
        <img src="images/facial_recognition_bias.png" alt="Facial Recognition Bias">
        <p>Facial Recognition Bias – AI struggles to recognize darker skin tones, leading to misidentifications.</p>
        <img src="images/ai_hiring_bias.png" alt="AI Hiring Bias">
        <p>AI in Hiring – AI-driven hiring tools have been found to favor male applicants over female ones.</p>
        <img src="images/search_engine_bias.png" alt="Search Engine Bias">
        <p>Search Engine Bias – Search results can reinforce harmful stereotypes.</p>
    </section>
    
    <section id="impact">
        <h2>Why Digital Bias Matters</h2>
        <p>Digital bias isn’t just a flaw; it has real-world consequences. AI systems influence critical aspects of society, and biased systems can cause discrimination, reinforce inequalities, and erode trust in technology.</p>
        <img src="images/ai_fairness_balance.png" alt="AI Fairness Balance">
        <h3>Key Impacts of Digital Bias</h3>
        <ul>
            <li>✅ <strong>Unfair Treatment</strong> – AI-driven hiring and loan approval systems can discriminate based on race, gender, or other factors.</li>
            <li>✅ <strong>Erosion of Trust</strong> – When people recognize biased outcomes, they lose confidence in technology.</li>
            <li>✅ <strong>Amplification of Inequality</strong> – If left unchecked, digital bias can deepen social divides rather than close them.</li>
        </ul>
    </section>
    
    <section id="solutions">
        <h2>How Can We Reduce Digital Bias?</h2>
        <p>Companies, developers, and policymakers must work together to ensure technology is fair and inclusive. Here are key strategies:</p>
        <ul>
            <li>1️⃣ <strong>Diverse and Representative Data</strong> – AI models must be trained on datasets that reflect a broad spectrum of people.</li>
            <li>2️⃣ <strong>Transparency and Accountability</strong> – Companies should disclose how their algorithms make decisions.</li>
            <li>3️⃣ <strong>Ethical AI Practices</strong> – Developers must follow fairness guidelines like IBM’s AI Fairness 360 Toolkit.</li>
            <li>4️⃣ <strong>Inclusive Design</strong> – Products should be designed with input from diverse communities to prevent exclusion.</li>
        </ul>
        <img src="images/ai_fairness_team.jpg" alt="AI Fairness Team">
    </section>
    
    <section id="references">
        <h2>References (APA 7th Edition Format)</h2>
        <ul>
            <li>Dastin, J. (2018). Amazon scraps secret AI recruiting tool that showed bias against women. Reuters. <a href="https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/" target="_blank">Link</a></li>
            <li>Grother, P., Ngan, M., & Hanaoka, K. (2019). Face recognition vendor test (FRVT) part 3: Demographic effects. National Institute of Standards and Technology. <a href="https://nvlpubs.nist.gov/nistpubs/ir/2019/nist.ir.8280.pdf" target="_blank">Link</a></li>
            <li>IBM Research. (2021). AI Fairness 360: An open-source toolkit to help detect and mitigate bias in machine learning models. <a href="https://research.ibm.com/blog/ai-fairness-360" target="_blank">Link</a></li>
        </ul>
    </section>
    
    <footer>
        <p>&copy; 2025 Your Name | All Rights Reserved</p>
    </footer>
</body>
</html>
