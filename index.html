<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>The Hidden Bias in Technology</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            line-height: 1.6;
            background: linear-gradient(to right, #2c3e50, #4ca1af);
            color: white;
            text-align: center;
        }
        header {
            background: rgba(0, 0, 0, 0.8);
            color: #fff;
            padding: 30px;
            font-size: 24px;
        }
        section {
            padding: 40px;
            max-width: 900px;
            margin: auto;
            opacity: 0;
            transform: translateY(20px);
            animation: fadeInUp 1s ease-out forwards;
            text-align: left;
        }
        img {
            max-width: 100%;
            display: block;
            margin: 20px auto;
            border-radius: 10px;
        }
        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }
        footer {
            background: rgba(0, 0, 0, 0.8);
            color: #fff;
            text-align: center;
            padding: 15px;
            position: relative;
            bottom: 0;
            width: 100%;
        }
    </style>
</head>
<body>
    <header>
        <h1>The Hidden Bias in Technology: Understanding and Addressing Digital Bias</h1>
        <p><em>Technology is not neutral. Learn how digital bias affects AI and society.</em></p>
    </header>
    
    <img src="images/ai_data_bias.png" alt="AI Data Bias">
    
    <section id="introduction">
        <h2>Introduction</h2>
        <p>Artificial Intelligence (AI) and digital systems influence everything from hiring decisions to policing and healthcare. However, biases embedded in these systems can reinforce existing inequalities. This website explores digital bias, its causes, real-world impact, and solutions to ensure fair technology for all.</p>
    </section>
    
    <section id="examples">
        <h2>Real-World Examples of Digital Bias</h2>
        <img src="images/facial_recognition_bias.png" alt="Facial Recognition Bias">
        <p>Facial Recognition Bias – AI struggles to recognize darker skin tones, leading to misidentifications.</p>
        <img src="images/ai_hiring_bias.png" alt="AI Hiring Bias">
        <p>AI in Hiring – AI-driven hiring tools have been found to favor male applicants over female ones.</p>
        <img src="images/search_engine_bias.png" alt="Search Engine Bias">
        <p>Search Engine Bias – Search results can reinforce harmful stereotypes.</p>
    </section>
    
    <section id="impact">
        <h2>Why Digital Bias Matters</h2>
        <p>Digital bias isn’t just a flaw; it has real-world consequences. AI systems influence critical aspects of society, and biased systems can cause discrimination, reinforce inequalities, and erode trust in technology.</p>
        <img src="images/ai_fairness_balance.png" alt="AI Fairness Balance">
    </section>
    
    <section id="solutions">
        <h2>How Can We Reduce Digital Bias?</h2>
        <p>Companies, developers, and policymakers must work together to ensure technology is fair and inclusive. Here are key strategies:</p>
        <ul>
            <li>1️⃣ <strong>Diverse and Representative Data</strong> – AI models must be trained on datasets that reflect a broad spectrum of people.</li>
            <li>2️⃣ <strong>Transparency and Accountability</strong> – Companies should disclose how their algorithms make decisions.</li>
            <li>3️⃣ <strong>Ethical AI Practices</strong> – Developers must follow fairness guidelines like IBM’s AI Fairness 360 Toolkit.</li>
            <li>4️⃣ <strong>Inclusive Design</strong> – Products should be designed with input from diverse communities to prevent exclusion.</li>
        </ul>
        <img src="images/ai_fairness_team.jpg" alt="AI Fairness Team">
    </section>
    
    <section id="references">
        <h2>References (APA 7th Edition Format)</h2>
        <ul>
            <li>Dastin, J. (2018). Amazon scraps secret AI recruiting tool that showed bias against women. Reuters. <a href="https://www.reuters.com/article/world/insight-amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK0AG/" target="_blank">Link</a></li>
            <li>Grother, P., Ngan, M., & Hanaoka, K. (2019). Face recognition vendor test (FRVT) part 3: Demographic effects. National Institute of Standards and Technology. <a href="https://nvlpubs.nist.gov/nistpubs/ir/2019/nist.ir.8280.pdf" target="_blank">Link</a></li>
            <li>IBM Research. (2021). AI Fairness 360: An open-source toolkit to help detect and mitigate bias in machine learning models. <a href="https://research.ibm.com/blog/ai-fairness-360" target="_blank">Link</a></li>
            <li>Noble, S. U. (2018). Algorithms of oppression: How search engines reinforce racism. NYU Press.</li>
            <li>O'Neil, C. (2016). Weapons of math destruction: How big data increases inequality and threatens democracy. Crown Publishing.</li>
        </ul>
    </section>
    
    <footer>
        <p>&copy; 2025 Your Name | All Rights Reserved</p>
    </footer>
</body>
</html>
